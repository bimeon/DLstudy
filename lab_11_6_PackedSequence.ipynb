{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMB2qb7FUO6IsM7ENQgcsDi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SeohyunLee0321/DLstudy/blob/main/lab_11_6_PackedSequence.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LEWBAJNb8Bop"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from torch.nn.utils.rnn import pad_sequence, pack_sequence, pack_padded_sequence, pad_packed_sequence"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Random word from random word generator\n",
        "data = ['hello world',\n",
        "        'midnight',\n",
        "        'calculation',\n",
        "        'path',\n",
        "        'short circuit']\n",
        "\n",
        "# Make dictionary\n",
        "char_set = ['<pad>'] + list(set(char for seq in data for char in seq)) # Get all characters and include pad token\n",
        "char2idx = {char: idx for idx, char in enumerate(char_set)} # Constuct character to index dictionary\n",
        "print('char_set:', char_set)\n",
        "print('char_set length:', len(char_set))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8pKisuMy8HpC",
        "outputId": "822e0482-fbb8-4fcb-9ae0-1fc9835952c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "char_set: ['<pad>', 'i', 'g', 'h', 'o', 'p', ' ', 'e', 'r', 'd', 'm', 't', 'c', 'a', 'u', 's', 'n', 'w', 'l']\n",
            "char_set length: 19\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert character to index and make list of tensors\n",
        "X = [torch.LongTensor([char2idx[char] for char in seq]) for seq in data]\n",
        "\n",
        "# Check converted result\n",
        "for sequence in X:\n",
        "    print(sequence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JkfLCyip8Jqq",
        "outputId": "649b2d1e-d091-428f-c3d0-87fa2ba922c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 3,  7, 18, 18,  4,  6, 17,  4,  8, 18,  9])\n",
            "tensor([10,  1,  9, 16,  1,  2,  3, 11])\n",
            "tensor([12, 13, 18, 12, 14, 18, 13, 11,  1,  4, 16])\n",
            "tensor([ 5, 13, 11,  3])\n",
            "tensor([15,  3,  4,  8, 11,  6, 12,  1,  8, 12, 14,  1, 11])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make length tensor (will be used later in 'pack_padded_sequence' function)\n",
        "lengths = [len(seq) for seq in X]\n",
        "print('lengths:', lengths)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "omTTaLcy8Kyl",
        "outputId": "4af76e2e-4c63-48a9-a664-f884a054191d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "lengths: [11, 8, 11, 4, 13]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make a Tensor of shape (Batch x Maximum_Sequence_Length)\n",
        "padded_sequence = pad_sequence(X, batch_first=True) # X is now padded sequence\n",
        "print(padded_sequence)\n",
        "print(padded_sequence.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "24n2IiIR8NE9",
        "outputId": "cd81aff3-18eb-4ce9-eeae-7a176a6ee033"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 3,  7, 18, 18,  4,  6, 17,  4,  8, 18,  9,  0,  0],\n",
            "        [10,  1,  9, 16,  1,  2,  3, 11,  0,  0,  0,  0,  0],\n",
            "        [12, 13, 18, 12, 14, 18, 13, 11,  1,  4, 16,  0,  0],\n",
            "        [ 5, 13, 11,  3,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
            "        [15,  3,  4,  8, 11,  6, 12,  1,  8, 12, 14,  1, 11]])\n",
            "torch.Size([5, 13])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# pack_sequence 함수를 이용하여 PackedSequence 만들기"
      ],
      "metadata": {
        "id": "iTUA7g2j9Cj7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "input (list of Tensor)는 길이에 따른 내림차순으로 정렬이 되어있어야"
      ],
      "metadata": {
        "id": "rDf3tnFx9Aq_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Sort by descending lengths\n",
        "sorted_idx = sorted(range(len(lengths)), key=lengths.__getitem__, reverse=True)\n",
        "sorted_X = [X[idx] for idx in sorted_idx]\n",
        "\n",
        "# Check converted result\n",
        "for sequence in sorted_X:\n",
        "    print(sequence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Od4WKaqD8Or_",
        "outputId": "30465b5f-daf6-49b4-b7e7-563d5356abdd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([15,  3,  4,  8, 11,  6, 12,  1,  8, 12, 14,  1, 11])\n",
            "tensor([ 3,  7, 18, 18,  4,  6, 17,  4,  8, 18,  9])\n",
            "tensor([12, 13, 18, 12, 14, 18, 13, 11,  1,  4, 16])\n",
            "tensor([10,  1,  9, 16,  1,  2,  3, 11])\n",
            "tensor([ 5, 13, 11,  3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "pack_sequence를 이용하여 PackedSequence를 만들"
      ],
      "metadata": {
        "id": "MoWkhXvH89uy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "packed_sequence = pack_sequence(sorted_X)\n",
        "print(packed_sequence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kd9UBkG78QUX",
        "outputId": "d045c4d2-1148-407a-8e9f-ce7ded73453c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PackedSequence(data=tensor([15,  3, 12, 10,  5,  3,  7, 13,  1, 13,  4, 18, 18,  9, 11,  8, 18, 12,\n",
            "        16,  3, 11,  4, 14,  1,  6,  6, 18,  2, 12, 17, 13,  3,  1,  4, 11, 11,\n",
            "         8,  8,  1, 12, 18,  4, 14,  9, 16,  1, 11]), batch_sizes=tensor([5, 5, 5, 5, 4, 4, 4, 4, 3, 3, 3, 1, 1]), sorted_indices=None, unsorted_indices=None)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Embedding 적용해보기"
      ],
      "metadata": {
        "id": "vA6_H1t8853w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "one-hot character embedding"
      ],
      "metadata": {
        "id": "dyeTVPfe85a8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# one-hot embedding using PaddedSequence\n",
        "eye = torch.eye(len(char_set)) # Identity matrix of shape (len(char_set), len(char_set))\n",
        "embedded_tensor = eye[padded_sequence]\n",
        "print(embedded_tensor.shape) # shape: (Batch_size, max_sequence_length, number_of_input_tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AvVIdWTk8R1o",
        "outputId": "7b4fe749-5f25-46e8-c076-0f3759441291"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([5, 13, 19])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# one-hot embedding using PackedSequence\n",
        "embedded_packed_seq = pack_sequence([eye[X[idx]] for idx in sorted_idx])\n",
        "print(embedded_packed_seq.data.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Byw8leeq8TdG",
        "outputId": "ce2e25e5-480e-43ee-e4b7-3a526605e644"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([47, 19])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# RNN 모델 만들기"
      ],
      "metadata": {
        "id": "AosM4RHA8yfu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "PaddedSequence를 이용하여 RNN에 넣기"
      ],
      "metadata": {
        "id": "hZ8SZhkN8uoB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# declare RNN\n",
        "rnn = torch.nn.RNN(input_size=len(char_set), hidden_size=30, batch_first=True)\n",
        "\n",
        "rnn_output, hidden = rnn(embedded_tensor)\n",
        "print(rnn_output.shape) # shape: (batch_size, max_seq_length, hidden_size)\n",
        "print(hidden.shape)     # shape: (num_layers * num_directions, batch_size, hidden_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Px7mzO528Vmu",
        "outputId": "bd9903e5-23cd-41c8-afa2-38bcce1d4bad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([5, 13, 30])\n",
            "torch.Size([1, 5, 30])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "PackedSequence를 이용하여 RNN에 넣기"
      ],
      "metadata": {
        "id": "XQqjJCnn8sm1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rnn_output, hidden = rnn(embedded_packed_seq)\n",
        "print(rnn_output.data.shape)\n",
        "print(hidden.data.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fHxJhCfP8XBD",
        "outputId": "1b5003fb-d71c-4062-98b2-ae880ad296fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([47, 30])\n",
            "torch.Size([1, 5, 30])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "unpacked_sequence, seq_lengths = pad_packed_sequence(embedded_packed_seq, batch_first=True)\n",
        "print(unpacked_sequence.shape)\n",
        "print(seq_lengths)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yr2yZGm-8ZzE",
        "outputId": "ff47253e-7d97-4e75-ce6e-25128513c92a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([5, 13, 19])\n",
            "tensor([13, 11, 11,  8,  4])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "PaddedSequence가 아까 길이에 따른 내림차순으로 정렬되어야 하기 때문에 재정렬"
      ],
      "metadata": {
        "id": "K7hf3Vrg8jPO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embedded_padded_sequence = eye[pad_sequence(sorted_X, batch_first=True)]\n",
        "print(embedded_padded_sequence.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fdx--jjt8bcD",
        "outputId": "3a6fa424-c246-4814-81db-ec52d2c7fef4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([5, 13, 19])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "padding이 된 Tensor를 PackedSequence로 변환"
      ],
      "metadata": {
        "id": "1UxBXssx8ej4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sorted_lengths = sorted(lengths, reverse=True)\n",
        "new_packed_sequence = pack_padded_sequence(embedded_padded_sequence, sorted_lengths, batch_first=True)\n",
        "print(new_packed_sequence.data.shape)\n",
        "print(new_packed_sequence.batch_sizes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J9i-Y9lB8ckH",
        "outputId": "d88ac3d5-5012-4cb3-8036-d0ff02aeda7f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([47, 19])\n",
            "tensor([5, 5, 5, 5, 4, 4, 4, 4, 3, 3, 3, 1, 1])\n"
          ]
        }
      ]
    }
  ]
}